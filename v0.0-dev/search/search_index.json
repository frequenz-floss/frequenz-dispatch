{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Dispatch Highlevel Interface","text":""},{"location":"#introduction","title":"Introduction","text":"<p>A highlevel interface for the dispatch API. The interface is made of the dispatch actor which should run once per microgrid. It provides two channels for clients: - \"new_dispatches\" for newly created dispatches - \"ready_dispatches\" for dispatches that are ready to be executed</p>"},{"location":"#example-usage","title":"Example Usage","text":"<pre><code>    async def run():\n        # dispatch helper sends out dispatches when they are due\n        dispatch_arrived = dispatch_helper.updated_dispatches().new_receiver()\n        dispatch_ready = dispatch_helper.ready_dispatches().new_receiver()\n\n        async for selected in select(dispatch_ready, dispatch_arrived):\n            if selected_from(selected, dispatch_ready):\n                dispatch = selected.value\n                match dispatch.type:\n                    case DISPATCH_TYPE_BATTERY_CHARGE:\n                        battery_pool = microgrid.battery_pool(dispatch.battery_set, task_id)\n                        battery_pool.set_charge(dispatch.power)\n                ...\n            if selected_from(selected, dispatch_arrived):\n                match selected.value:\n                    case Created(dispatch):\n                        log.info(\"New dispatch arrived %s\", dispatch)\n                        ...\n                    case Updated(dispatch):\n                        log.info(\"Dispatch updated %s\", dispatch)\n                        ...\n                    case Deleted(dispatch):\n                        log.info(\"Dispatch deleted %s\", dispatch)\n                        ...\n</code></pre>"},{"location":"#supported-platforms","title":"Supported Platforms","text":"<p>The following platforms are officially supported (tested):</p> <ul> <li>Python: 3.11</li> <li>Operating System: Ubuntu Linux 20.04</li> <li>Architectures: amd64, arm64</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>If you want to know how to build this project and contribute to it, please check out the Contributing Guide.</p>"},{"location":"CONTRIBUTING/","title":"Contributing to Dispatch Highlevel Interface","text":""},{"location":"CONTRIBUTING/#build","title":"Build","text":"<p>You can use <code>build</code> to simply build the source and binary distribution:</p> <pre><code>python -m pip install build\npython -m build\n</code></pre>"},{"location":"CONTRIBUTING/#local-development","title":"Local development","text":"<p>You can use editable installs to develop the project locally (it will install all the dependencies too):</p> <pre><code>python -m pip install -e .\n</code></pre> <p>Or you can install all development dependencies (<code>mypy</code>, <code>pylint</code>, <code>pytest</code>, etc.) in one go too: <pre><code>python -m pip install -e .[dev]\n</code></pre></p> <p>If you don't want to install all the dependencies, you can also use <code>nox</code> to run the tests and other checks creating its own virtual environments:</p> <pre><code>python -m pip install .[dev-noxfile]\nnox\n</code></pre> <p>You can also use <code>nox -R</code> to reuse the current testing environment to speed up test at the expense of a higher chance to end up with a dirty test environment.</p>"},{"location":"CONTRIBUTING/#running-tests-checks-individually","title":"Running tests / checks individually","text":"<p>For a better development test cycle you can install the runtime and test dependencies and run <code>pytest</code> manually.</p> <pre><code>python -m pip install .[dev-pytest]  # included in .[dev] too\n\n# And for example\npytest tests/test_*.py\n</code></pre> <p>Or you can use <code>nox</code>:</p> <pre><code>nox -R -s pytest -- test/test_*.py\n</code></pre> <p>The same appliest to <code>pylint</code> or <code>mypy</code> for example:</p> <pre><code>nox -R -s pylint -- test/test_*.py\nnox -R -s mypy -- test/test_*.py\n</code></pre>"},{"location":"CONTRIBUTING/#building-the-documentation","title":"Building the documentation","text":"<p>To build the documentation, first install the dependencies (if you didn't install all <code>dev</code> dependencies):</p> <pre><code>python -m pip install -e .[dev-mkdocs]\n</code></pre> <p>Then you can build the documentation (it will be written in the <code>site/</code> directory):</p> <pre><code>mkdocs build\n</code></pre> <p>Or you can just serve the documentation without building it using:</p> <pre><code>mkdocs serve\n</code></pre> <p>Your site will be updated live when you change your files (provided that you used <code>pip install -e .</code>, beware of a common pitfall of using <code>pip install</code> without <code>-e</code>, in that case the API reference won't change unless you do a new <code>pip install</code>).</p> <p>To build multi-version documentation, we use mike. If you want to see how the multi-version sites looks like locally, you can use:</p> <pre><code>mike deploy my-version\nmike set-default my-version\nmike serve\n</code></pre> <p><code>mike</code> works in mysterious ways. Some basic information:</p> <ul> <li><code>mike deploy</code> will do a <code>mike build</code> and write the results to your local <code>gh-pages</code> branch. <code>my-version</code> is an arbitrary name for the local version   you want to preview.</li> <li><code>mike set-default</code> is needed so when you serve the documentation, it goes to   your newly produced documentation by default.</li> <li><code>mike serve</code> will serve the contents of your local <code>gh-pages</code> branch. Be   aware that, unlike <code>mkdocs serve</code>, changes to the sources won't be shown   live, as the <code>mike deploy</code> step is needed to refresh them.</li> </ul> <p>Be careful not to use <code>--push</code> with <code>mike deploy</code>, otherwise it will push your local <code>gh-pages</code> branch to the <code>origin</code> remote.</p> <p>That said, if you want to test the actual website in your fork, you can always use <code>mike deploy --push --remote your-fork-remote</code>, and then access the GitHub pages produced for your fork.</p>"},{"location":"CONTRIBUTING/#releasing","title":"Releasing","text":"<p>These are the steps to create a new release:</p> <ol> <li> <p>Get the latest head you want to create a release from.</p> </li> <li> <p>Update the <code>RELEASE_NOTES.md</code> file if it is not complete, up to date, and    remove template comments (<code>&lt;!-- ... -&gt;</code>) and empty sections. Submit a pull    request if an update is needed, wait until it is merged, and update the    latest head you want to create a release from to get the new merged pull    request.</p> </li> <li> <p>Create a new signed tag using the release notes and    a semver compatible version number with a <code>v</code> prefix,    for example:</p> </li> </ol> <pre><code>git tag -s --cleanup=whitespace -F RELEASE_NOTES.md v0.0.1\n</code></pre> <ol> <li> <p>Push the new tag.</p> </li> <li> <p>A GitHub action will test the tag and if all goes well it will create    a GitHub    Release,    and upload a new package to    PyPI    automatically.</p> </li> <li> <p>Once this is done, reset the <code>RELEASE_NOTES.md</code> with the template:</p> </li> </ol> <pre><code>cp .github/RELEASE_NOTES.template.md RELEASE_NOTES.md\n</code></pre> <p>Commit the new release notes and create a PR (this step should be automated    eventually too).</p> <ol> <li>Celebrate!</li> </ol>"},{"location":"CONTRIBUTING/#cross-arch-testing","title":"Cross-Arch Testing","text":"<p>This project has built-in support for testing across multiple architectures. Currently, our CI conducts tests on <code>arm64</code> machines using QEMU emulation. We also have the flexibility to expand this support to include additional architectures in the future.</p> <p>This project contains Dockerfiles that can be used in the CI to test the python package in non-native machine architectures, e.g., <code>arm64</code>. The Dockerfiles exist in the directory <code>.github/containers/nox-cross-arch</code>, and follow a naming scheme so that they can be easily used in build matrices in the CI, in <code>nox-cross-arch</code> job. The naming scheme is:</p> <pre><code>&lt;arch&gt;-&lt;os&gt;-python-&lt;python-version&gt;.Dockerfile\n</code></pre> <p>E.g.,</p> <pre><code>arm64-ubuntu-20.04-python-3.11.Dockerfile\n</code></pre> <p>If a Dockerfile for your desired target architecture, OS, and python version does not exist here, please add one before proceeding to add your options to the test matrix.</p>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Home</li> <li>API Reference</li> <li>Contributing</li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>frequenz<ul> <li>dispatch<ul> <li>actor</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/frequenz/dispatch/","title":"Index","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch","title":"frequenz.dispatch","text":"<p>A highlevel interface for the dispatch API.</p>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch-attributes","title":"Attributes","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.DispatchEvent","title":"frequenz.dispatch.DispatchEvent  <code>module-attribute</code>","text":"<pre><code>DispatchEvent = Created | Updated | Deleted\n</code></pre> <p>Type that is sent over the channel for dispatch updates.</p> <p>This type is used to send dispatches that were created, updated or deleted over the channel.</p>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch-classes","title":"Classes","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Created","title":"frequenz.dispatch.Created  <code>dataclass</code>","text":"<p>A dispatch created event.</p> Source code in <code>frequenz/dispatch/_event.py</code> <pre><code>@dataclass(frozen=True)\nclass Created:\n    \"\"\"A dispatch created event.\"\"\"\n\n    dispatch: Dispatch\n    \"\"\"The dispatch that was created.\"\"\"\n</code></pre>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Created-attributes","title":"Attributes","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Created.dispatch","title":"dispatch  <code>instance-attribute</code>","text":"<pre><code>dispatch: Dispatch\n</code></pre> <p>The dispatch that was created.</p>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Deleted","title":"frequenz.dispatch.Deleted  <code>dataclass</code>","text":"<p>A dispatch deleted event.</p> Source code in <code>frequenz/dispatch/_event.py</code> <pre><code>@dataclass(frozen=True)\nclass Deleted:\n    \"\"\"A dispatch deleted event.\"\"\"\n\n    dispatch: Dispatch\n    \"\"\"The dispatch that was deleted.\"\"\"\n</code></pre>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Deleted-attributes","title":"Attributes","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Deleted.dispatch","title":"dispatch  <code>instance-attribute</code>","text":"<pre><code>dispatch: Dispatch\n</code></pre> <p>The dispatch that was deleted.</p>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Dispatcher","title":"frequenz.dispatch.Dispatcher","text":"<p>A highlevel interface for the dispatch API.</p> <p>This class provides a highlevel interface to the dispatch API. It provides two channels:</p> <p>One that sends a dispatch event message whenever a dispatch is created, updated or deleted.</p> <p>The other sends a dispatch message whenever a dispatch is ready to be executed according to the schedule.</p> <p>allows to receive new dispatches and ready dispatches.</p> Processing ready-to-execute dispatches <pre><code>import grpc.aio\n\nasync def run():\n    grpc_channel = grpc.aio.insecure_channel(\"localhost:50051\")\n    microgrid_id = 1\n    service_address = \"localhost:50051\"\n\n    dispatcher = Dispatcher(microgrid_id, grpc_channel, service_address)\n    dispatcher.start()  # this will start the actor\n\n    ready_receiver = dispatcher.ready_to_execute.new_receiver()\n\n    async for dispatch in ready_receiver:\n        print(f\"Executing dispatch {dispatch.id}, due on {dispatch.start_time}\")\n        # execute the dispatch\n</code></pre> Getting notification about dispatch lifecycle events <pre><code>from typing import assert_never\n\nimport grpc.aio\nfrom frequenz.dispatch import Created, Deleted, Dispatcher, Updated\n\n\nasync def run():\n    grpc_channel = grpc.aio.insecure_channel(\"localhost:50051\")\n    microgrid_id = 1\n    service_address = \"localhost:50051\"\n    dispatcher = Dispatcher(microgrid_id, grpc_channel, service_address)\n    dispatcher.start()  # this will start the actor\n\n    events_receiver = dispatcher.lifecycle_events.new_receiver()\n\n    async for event in events_receiver:\n        match event:\n            case Created(dispatch):\n                print(f\"A dispatch was created: {dispatch}\")\n            case Deleted(dispatch):\n                print(f\"A dispatch was deleted: {dispatch}\")\n            case Updated(dispatch):\n                print(f\"A dispatch was updated: {dispatch}\")\n            case _ as unhandled:\n                assert_never(unhandled)\n</code></pre> Source code in <code>frequenz/dispatch/_dispatcher.py</code> <pre><code>class Dispatcher:\n    \"\"\"A highlevel interface for the dispatch API.\n\n    This class provides a highlevel interface to the dispatch API.\n    It provides two channels:\n\n    One that sends a dispatch event message whenever a dispatch is created, updated or deleted.\n\n    The other sends a dispatch message whenever a dispatch is ready to be\n    executed according to the schedule.\n\n    allows to receive new dispatches and ready dispatches.\n\n    Example: Processing ready-to-execute dispatches\n        ```python\n        import grpc.aio\n\n        async def run():\n            grpc_channel = grpc.aio.insecure_channel(\"localhost:50051\")\n            microgrid_id = 1\n            service_address = \"localhost:50051\"\n\n            dispatcher = Dispatcher(microgrid_id, grpc_channel, service_address)\n            dispatcher.start()  # this will start the actor\n\n            ready_receiver = dispatcher.ready_to_execute.new_receiver()\n\n            async for dispatch in ready_receiver:\n                print(f\"Executing dispatch {dispatch.id}, due on {dispatch.start_time}\")\n                # execute the dispatch\n        ```\n\n    Example: Getting notification about dispatch lifecycle events\n        ```python\n        from typing import assert_never\n\n        import grpc.aio\n        from frequenz.dispatch import Created, Deleted, Dispatcher, Updated\n\n\n        async def run():\n            grpc_channel = grpc.aio.insecure_channel(\"localhost:50051\")\n            microgrid_id = 1\n            service_address = \"localhost:50051\"\n            dispatcher = Dispatcher(microgrid_id, grpc_channel, service_address)\n            dispatcher.start()  # this will start the actor\n\n            events_receiver = dispatcher.lifecycle_events.new_receiver()\n\n            async for event in events_receiver:\n                match event:\n                    case Created(dispatch):\n                        print(f\"A dispatch was created: {dispatch}\")\n                    case Deleted(dispatch):\n                        print(f\"A dispatch was deleted: {dispatch}\")\n                    case Updated(dispatch):\n                        print(f\"A dispatch was updated: {dispatch}\")\n                    case _ as unhandled:\n                        assert_never(unhandled)\n        ```\n    \"\"\"\n\n    def __init__(\n        self, microgrid_id: int, grpc_channel: grpc.aio.Channel, svc_addr: str\n    ):\n        \"\"\"Initialize the dispatcher.\n\n        Args:\n            microgrid_id: The microgrid id.\n            grpc_channel: The gRPC channel.\n            svc_addr: The service address.\n        \"\"\"\n        self._ready_channel = Broadcast[Dispatch](name=\"ready_dispatches\")\n        self._updated_channel = Broadcast[DispatchEvent](name=\"new_dispatches\")\n        self._actor = DispatchingActor(\n            microgrid_id,\n            grpc_channel,\n            svc_addr,\n            self._updated_channel.new_sender(),\n            self._ready_channel.new_sender(),\n        )\n\n    async def start(self) -&gt; None:\n        \"\"\"Start the actor.\"\"\"\n        self._actor.start()\n\n    @property\n    def lifecycle_events(self) -&gt; ReceiverFetcher[DispatchEvent]:\n        \"\"\"Return new, updated or deleted dispatches receiver.\n\n        Returns:\n            A new receiver for new dispatches.\n        \"\"\"\n        return self._updated_channel\n\n    @property\n    def ready_to_execute(self) -&gt; ReceiverFetcher[Dispatch]:\n        \"\"\"Return ready dispatches receiver.\n\n        Returns:\n            A new receiver for ready dispatches.\n        \"\"\"\n        return self._ready_channel\n</code></pre>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Dispatcher-attributes","title":"Attributes","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Dispatcher.lifecycle_events","title":"lifecycle_events  <code>property</code>","text":"<pre><code>lifecycle_events: ReceiverFetcher[DispatchEvent]\n</code></pre> <p>Return new, updated or deleted dispatches receiver.</p> RETURNS DESCRIPTION <code>ReceiverFetcher[DispatchEvent]</code> <p>A new receiver for new dispatches.</p>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Dispatcher.ready_to_execute","title":"ready_to_execute  <code>property</code>","text":"<pre><code>ready_to_execute: ReceiverFetcher[Dispatch]\n</code></pre> <p>Return ready dispatches receiver.</p> RETURNS DESCRIPTION <code>ReceiverFetcher[Dispatch]</code> <p>A new receiver for ready dispatches.</p>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Dispatcher-functions","title":"Functions","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Dispatcher.__init__","title":"__init__","text":"<pre><code>__init__(\n    microgrid_id: int, grpc_channel: Channel, svc_addr: str\n)\n</code></pre> <p>Initialize the dispatcher.</p> PARAMETER DESCRIPTION <code>microgrid_id</code> <p>The microgrid id.</p> <p> TYPE: <code>int</code> </p> <code>grpc_channel</code> <p>The gRPC channel.</p> <p> TYPE: <code>Channel</code> </p> <code>svc_addr</code> <p>The service address.</p> <p> TYPE: <code>str</code> </p> Source code in <code>frequenz/dispatch/_dispatcher.py</code> <pre><code>def __init__(\n    self, microgrid_id: int, grpc_channel: grpc.aio.Channel, svc_addr: str\n):\n    \"\"\"Initialize the dispatcher.\n\n    Args:\n        microgrid_id: The microgrid id.\n        grpc_channel: The gRPC channel.\n        svc_addr: The service address.\n    \"\"\"\n    self._ready_channel = Broadcast[Dispatch](name=\"ready_dispatches\")\n    self._updated_channel = Broadcast[DispatchEvent](name=\"new_dispatches\")\n    self._actor = DispatchingActor(\n        microgrid_id,\n        grpc_channel,\n        svc_addr,\n        self._updated_channel.new_sender(),\n        self._ready_channel.new_sender(),\n    )\n</code></pre>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Dispatcher.start","title":"start  <code>async</code>","text":"<pre><code>start() -&gt; None\n</code></pre> <p>Start the actor.</p> Source code in <code>frequenz/dispatch/_dispatcher.py</code> <pre><code>async def start(self) -&gt; None:\n    \"\"\"Start the actor.\"\"\"\n    self._actor.start()\n</code></pre>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.ReceiverFetcher","title":"frequenz.dispatch.ReceiverFetcher","text":"<p>             Bases: <code>Protocol[ReceivedT_co]</code></p> <p>An interface that just exposes a <code>new_receiver</code> method.</p> Source code in <code>frequenz/dispatch/_dispatcher.py</code> <pre><code>class ReceiverFetcher(Protocol[ReceivedT_co]):\n    \"\"\"An interface that just exposes a `new_receiver` method.\"\"\"\n\n    @abc.abstractmethod\n    def new_receiver(\n        self, *, name: str | None = None, limit: int = 50\n    ) -&gt; Receiver[ReceivedT_co]:\n        \"\"\"Get a receiver from the channel.\n\n        Args:\n            name: A name to identify the receiver in the logs.\n            limit: The maximum size of the receiver.\n\n        Returns:\n            A receiver instance.\n        \"\"\"\n</code></pre>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.ReceiverFetcher-functions","title":"Functions","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.ReceiverFetcher.new_receiver","title":"new_receiver  <code>abstractmethod</code>","text":"<pre><code>new_receiver(\n    *, name: str | None = None, limit: int = 50\n) -&gt; Receiver[ReceivedT_co]\n</code></pre> <p>Get a receiver from the channel.</p> PARAMETER DESCRIPTION <code>name</code> <p>A name to identify the receiver in the logs.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>limit</code> <p>The maximum size of the receiver.</p> <p> TYPE: <code>int</code> DEFAULT: <code>50</code> </p> RETURNS DESCRIPTION <code>Receiver[ReceivedT_co]</code> <p>A receiver instance.</p> Source code in <code>frequenz/dispatch/_dispatcher.py</code> <pre><code>@abc.abstractmethod\ndef new_receiver(\n    self, *, name: str | None = None, limit: int = 50\n) -&gt; Receiver[ReceivedT_co]:\n    \"\"\"Get a receiver from the channel.\n\n    Args:\n        name: A name to identify the receiver in the logs.\n        limit: The maximum size of the receiver.\n\n    Returns:\n        A receiver instance.\n    \"\"\"\n</code></pre>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Updated","title":"frequenz.dispatch.Updated  <code>dataclass</code>","text":"<p>A dispatch updated event.</p> Source code in <code>frequenz/dispatch/_event.py</code> <pre><code>@dataclass(frozen=True)\nclass Updated:\n    \"\"\"A dispatch updated event.\"\"\"\n\n    dispatch: Dispatch\n    \"\"\"The dispatch that was updated.\"\"\"\n</code></pre>"},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Updated-attributes","title":"Attributes","text":""},{"location":"reference/frequenz/dispatch/#frequenz.dispatch.Updated.dispatch","title":"dispatch  <code>instance-attribute</code>","text":"<pre><code>dispatch: Dispatch\n</code></pre> <p>The dispatch that was updated.</p>"},{"location":"reference/frequenz/dispatch/actor/","title":"actor","text":""},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor","title":"frequenz.dispatch.actor","text":"<p>The dispatch actor.</p>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor-attributes","title":"Attributes","text":""},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor-classes","title":"Classes","text":""},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor","title":"frequenz.dispatch.actor.DispatchingActor","text":"<p>             Bases: <code>Actor</code></p> <p>Dispatch actor.</p> <p>This actor is responsible for handling dispatches for a microgrid.</p> <p>This means staying in sync with the API and scheduling dispatches as necessary.</p> Source code in <code>frequenz/dispatch/actor.py</code> <pre><code>class DispatchingActor(Actor):\n    \"\"\"Dispatch actor.\n\n    This actor is responsible for handling dispatches for a microgrid.\n\n    This means staying in sync with the API and scheduling\n    dispatches as necessary.\n    \"\"\"\n\n    # pylint: disable=too-many-arguments\n    def __init__(\n        self,\n        microgrid_id: int,\n        grpc_channel: grpc.aio.Channel,\n        svc_addr: str,\n        updated_dispatch_sender: Sender[DispatchEvent],\n        ready_dispatch_sender: Sender[Dispatch],\n        poll_interval: timedelta = _DEFAULT_POLL_INTERVAL,\n    ) -&gt; None:\n        \"\"\"Initialize the actor.\n\n        Args:\n            microgrid_id: The microgrid ID to handle dispatches for.\n            grpc_channel: The gRPC channel to use for communication with the API.\n            svc_addr: Address of the service to connect to.\n            updated_dispatch_sender: A sender for new or updated dispatches.\n            ready_dispatch_sender: A sender for ready dispatches.\n            poll_interval: The interval to poll the API for dispatche changes.\n        \"\"\"\n        super().__init__(name=\"dispatch\")\n\n        self._client = Client(grpc_channel, svc_addr)\n        self._dispatches: dict[int, Dispatch] = {}\n        self._scheduled: dict[int, asyncio.Task[None]] = {}\n        self._microgrid_id = microgrid_id\n        self._updated_dispatch_sender = updated_dispatch_sender\n        self._ready_dispatch_sender = ready_dispatch_sender\n        self._poll_timer = Timer(poll_interval, SkipMissedAndDrift())\n\n    async def _run(self) -&gt; None:\n        \"\"\"Run the actor.\"\"\"\n        self._poll_timer.reset()\n        try:\n            async for _ in self._poll_timer:\n                await self._fetch()\n        except asyncio.CancelledError:\n            for task in self._scheduled.values():\n                task.cancel()\n            raise\n\n    async def _fetch(self) -&gt; None:\n        \"\"\"Fetch all relevant dispatches.\"\"\"\n        old_dispatches = self._dispatches\n        self._dispatches = {}\n\n        try:\n            _logger.info(\"Fetching dispatches for microgrid %s\", self._microgrid_id)\n            async for dispatch in self._client.list(microgrid_id=self._microgrid_id):\n                self._dispatches[dispatch.id] = dispatch\n\n                old_dispatch = old_dispatches.pop(dispatch.id, None)\n                if not old_dispatch:\n                    self._update_dispatch_schedule(dispatch, None)\n                    _logger.info(\"New dispatch: %s\", dispatch)\n                    await self._updated_dispatch_sender.send(Created(dispatch=dispatch))\n                elif dispatch.update_time != old_dispatch.update_time:\n                    self._update_dispatch_schedule(dispatch, old_dispatch)\n                    _logger.info(\"Updated dispatch: %s\", dispatch)\n                    await self._updated_dispatch_sender.send(Updated(dispatch=dispatch))\n\n        except grpc.aio.AioRpcError as error:\n            _logger.error(\"Error fetching dispatches: %s\", error)\n            self._dispatches = old_dispatches\n            return\n\n        for dispatch in old_dispatches.values():\n            _logger.info(\"Deleted dispatch: %s\", dispatch)\n            await self._updated_dispatch_sender.send(Deleted(dispatch=dispatch))\n            if task := self._scheduled.pop(dispatch.id, None):\n                task.cancel()\n\n    def _update_dispatch_schedule(\n        self, dispatch: Dispatch, old_dispatch: Dispatch | None\n    ) -&gt; None:\n        \"\"\"Update the schedule for a dispatch.\n\n        Schedules, reschedules or cancels the dispatch based on the start_time\n        and active status.\n\n        For example:\n            * when the start_time changes, the dispatch is rescheduled\n            * when the dispatch is deactivated, the dispatch is cancelled\n\n        Args:\n            dispatch: The dispatch to update the schedule for.\n            old_dispatch: The old dispatch, if available.\n        \"\"\"\n        if (\n            old_dispatch\n            and old_dispatch.active\n            and old_dispatch.start_time != dispatch.start_time\n        ):\n            if task := self._scheduled.pop(dispatch.id, None):\n                task.cancel()\n\n        if dispatch.active and dispatch.id not in self._scheduled:\n            self._scheduled[dispatch.id] = asyncio.create_task(\n                self._schedule_task(dispatch)\n            )\n\n    async def _schedule_task(self, dispatch: Dispatch) -&gt; None:\n        \"\"\"Wait for a dispatch to become ready.\n\n        Waits for the dispatches next run and then notifies that it is ready.\n\n        Args:\n            dispatch: The dispatch to schedule.\n        \"\"\"\n\n        def next_run_info() -&gt; tuple[datetime, datetime] | None:\n            now = datetime.now(tz=timezone.utc)\n            next_run = self.calculate_next_run(dispatch, now)\n\n            if next_run is None:\n                return None\n\n            return now, next_run\n\n        while pair := next_run_info():\n            now, next_time = pair\n\n            if next_time - now &gt; _MAX_AHEAD_SCHEDULE:\n                await asyncio.sleep(_MAX_AHEAD_SCHEDULE.total_seconds())\n                continue\n\n            _logger.info(\"Dispatch %s scheduled for %s\", dispatch.id, next_time)\n            await asyncio.sleep((next_time - now).total_seconds())\n\n            _logger.info(\"Dispatch ready: %s\", dispatch)\n            await self._ready_dispatch_sender.send(dispatch)\n\n        _logger.info(\"Dispatch finished: %s\", dispatch)\n        self._scheduled.pop(dispatch.id)\n\n    @classmethod\n    def calculate_next_run(cls, dispatch: Dispatch, _from: datetime) -&gt; datetime | None:\n        \"\"\"Calculate the next run of a dispatch.\n\n        Args:\n            dispatch: The dispatch to calculate the next run for.\n            _from: The time to calculate the next run from.\n\n        Returns:\n            The next run of the dispatch or None if the dispatch is finished.\n        \"\"\"\n        if (\n            not dispatch.recurrence.frequency\n            or dispatch.recurrence.frequency == Frequency.UNSPECIFIED\n        ):\n            if _from &gt; dispatch.start_time:\n                return None\n            return dispatch.start_time\n\n        # Make sure no weekday is UNSPECIFIED\n        if Weekday.UNSPECIFIED in dispatch.recurrence.byweekdays:\n            _logger.warning(\n                \"Dispatch %s has UNSPECIFIED weekday, ignoring...\", dispatch.id\n            )\n            return None\n\n        count, until = (None, None)\n        if end := dispatch.recurrence.end_criteria:\n            count = end.count\n            until = end.until\n\n        next_run = rrule.rrule(\n            freq=_RRULE_FREQ_MAP[dispatch.recurrence.frequency],\n            dtstart=dispatch.start_time,\n            count=count,\n            until=until,\n            byminute=dispatch.recurrence.byminutes,\n            byhour=dispatch.recurrence.byhours,\n            byweekday=[\n                _RRULE_WEEKDAY_MAP[weekday]\n                for weekday in dispatch.recurrence.byweekdays\n            ],\n            bymonthday=dispatch.recurrence.bymonthdays,\n            bymonth=dispatch.recurrence.bymonths,\n            interval=dispatch.recurrence.interval,\n        )\n\n        return cast(datetime | None, next_run.after(_from, inc=True))\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor-attributes","title":"Attributes","text":""},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.RESTART_DELAY","title":"RESTART_DELAY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RESTART_DELAY: timedelta = timedelta(seconds=2)\n</code></pre> <p>The delay to wait between restarts of this actor.</p>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.is_running","title":"is_running  <code>property</code>","text":"<pre><code>is_running: bool\n</code></pre> <p>Return whether this background service is running.</p> <p>A service is considered running when at least one task is running.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether this background service is running.</p>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>The name of this background service.</p> RETURNS DESCRIPTION <code>str</code> <p>The name of this background service.</p>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.tasks","title":"tasks  <code>property</code>","text":"<pre><code>tasks: Set[Task[Any]]\n</code></pre> <p>Return the set of running tasks spawned by this background service.</p> <p>Users typically should not modify the tasks in the returned set and only use them for informational purposes.</p> <p>Danger</p> <p>Changing the returned tasks may lead to unexpected behavior, don't do it unless the class explicitly documents it is safe to do so.</p> RETURNS DESCRIPTION <code>Set[Task[Any]]</code> <p>The set of running tasks spawned by this background service.</p>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor-functions","title":"Functions","text":""},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.__aenter__","title":"__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; Self\n</code></pre> <p>Enter an async context.</p> <p>Start this background service.</p> RETURNS DESCRIPTION <code>Self</code> <p>This background service.</p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>async def __aenter__(self) -&gt; Self:\n    \"\"\"Enter an async context.\n\n    Start this background service.\n\n    Returns:\n        This background service.\n    \"\"\"\n    self.start()\n    return self\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.__aexit__","title":"__aexit__  <code>async</code>","text":"<pre><code>__aexit__(\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: TracebackType | None,\n) -&gt; None\n</code></pre> <p>Exit an async context.</p> <p>Stop this background service.</p> PARAMETER DESCRIPTION <code>exc_type</code> <p>The type of the exception raised, if any.</p> <p> TYPE: <code>type[BaseException] | None</code> </p> <code>exc_val</code> <p>The exception raised, if any.</p> <p> TYPE: <code>BaseException | None</code> </p> <code>exc_tb</code> <p>The traceback of the exception raised, if any.</p> <p> TYPE: <code>TracebackType | None</code> </p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>async def __aexit__(\n    self,\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: TracebackType | None,\n) -&gt; None:\n    \"\"\"Exit an async context.\n\n    Stop this background service.\n\n    Args:\n        exc_type: The type of the exception raised, if any.\n        exc_val: The exception raised, if any.\n        exc_tb: The traceback of the exception raised, if any.\n    \"\"\"\n    await self.stop()\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.__await__","title":"__await__","text":"<pre><code>__await__() -&gt; Generator[None, None, None]\n</code></pre> <p>Await this background service.</p> <p>An awaited background service will wait for all its tasks to finish.</p> RETURNS DESCRIPTION <code>Generator[None, None, None]</code> <p>An implementation-specific generator for the awaitable.</p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>def __await__(self) -&gt; collections.abc.Generator[None, None, None]:\n    \"\"\"Await this background service.\n\n    An awaited background service will wait for all its tasks to finish.\n\n    Returns:\n        An implementation-specific generator for the awaitable.\n    \"\"\"\n    return self.wait().__await__()\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.__del__","title":"__del__","text":"<pre><code>__del__() -&gt; None\n</code></pre> <p>Destroy this instance.</p> <p>Cancel all running tasks spawned by this background service.</p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>def __del__(self) -&gt; None:\n    \"\"\"Destroy this instance.\n\n    Cancel all running tasks spawned by this background service.\n    \"\"\"\n    self.cancel(\"{self!r} was deleted\")\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.__init__","title":"__init__","text":"<pre><code>__init__(\n    microgrid_id: int,\n    grpc_channel: Channel,\n    svc_addr: str,\n    updated_dispatch_sender: Sender[DispatchEvent],\n    ready_dispatch_sender: Sender[Dispatch],\n    poll_interval: timedelta = _DEFAULT_POLL_INTERVAL,\n) -&gt; None\n</code></pre> <p>Initialize the actor.</p> PARAMETER DESCRIPTION <code>microgrid_id</code> <p>The microgrid ID to handle dispatches for.</p> <p> TYPE: <code>int</code> </p> <code>grpc_channel</code> <p>The gRPC channel to use for communication with the API.</p> <p> TYPE: <code>Channel</code> </p> <code>svc_addr</code> <p>Address of the service to connect to.</p> <p> TYPE: <code>str</code> </p> <code>updated_dispatch_sender</code> <p>A sender for new or updated dispatches.</p> <p> TYPE: <code>Sender[DispatchEvent]</code> </p> <code>ready_dispatch_sender</code> <p>A sender for ready dispatches.</p> <p> TYPE: <code>Sender[Dispatch]</code> </p> <code>poll_interval</code> <p>The interval to poll the API for dispatche changes.</p> <p> TYPE: <code>timedelta</code> DEFAULT: <code>_DEFAULT_POLL_INTERVAL</code> </p> Source code in <code>frequenz/dispatch/actor.py</code> <pre><code>def __init__(\n    self,\n    microgrid_id: int,\n    grpc_channel: grpc.aio.Channel,\n    svc_addr: str,\n    updated_dispatch_sender: Sender[DispatchEvent],\n    ready_dispatch_sender: Sender[Dispatch],\n    poll_interval: timedelta = _DEFAULT_POLL_INTERVAL,\n) -&gt; None:\n    \"\"\"Initialize the actor.\n\n    Args:\n        microgrid_id: The microgrid ID to handle dispatches for.\n        grpc_channel: The gRPC channel to use for communication with the API.\n        svc_addr: Address of the service to connect to.\n        updated_dispatch_sender: A sender for new or updated dispatches.\n        ready_dispatch_sender: A sender for ready dispatches.\n        poll_interval: The interval to poll the API for dispatche changes.\n    \"\"\"\n    super().__init__(name=\"dispatch\")\n\n    self._client = Client(grpc_channel, svc_addr)\n    self._dispatches: dict[int, Dispatch] = {}\n    self._scheduled: dict[int, asyncio.Task[None]] = {}\n    self._microgrid_id = microgrid_id\n    self._updated_dispatch_sender = updated_dispatch_sender\n    self._ready_dispatch_sender = ready_dispatch_sender\n    self._poll_timer = Timer(poll_interval, SkipMissedAndDrift())\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Return a string representation of this instance.</p> RETURNS DESCRIPTION <code>str</code> <p>A string representation of this instance.</p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of this instance.\n\n    Returns:\n        A string representation of this instance.\n    \"\"\"\n    return f\"{type(self).__name__}(name={self._name!r}, tasks={self._tasks!r})\"\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Return a string representation of this instance.</p> RETURNS DESCRIPTION <code>str</code> <p>A string representation of this instance.</p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of this instance.\n\n    Returns:\n        A string representation of this instance.\n    \"\"\"\n    return f\"{type(self).__name__}[{self._name}]\"\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.calculate_next_run","title":"calculate_next_run  <code>classmethod</code>","text":"<pre><code>calculate_next_run(\n    dispatch: Dispatch, _from: datetime\n) -&gt; datetime | None\n</code></pre> <p>Calculate the next run of a dispatch.</p> PARAMETER DESCRIPTION <code>dispatch</code> <p>The dispatch to calculate the next run for.</p> <p> TYPE: <code>Dispatch</code> </p> <code>_from</code> <p>The time to calculate the next run from.</p> <p> TYPE: <code>datetime</code> </p> RETURNS DESCRIPTION <code>datetime | None</code> <p>The next run of the dispatch or None if the dispatch is finished.</p> Source code in <code>frequenz/dispatch/actor.py</code> <pre><code>@classmethod\ndef calculate_next_run(cls, dispatch: Dispatch, _from: datetime) -&gt; datetime | None:\n    \"\"\"Calculate the next run of a dispatch.\n\n    Args:\n        dispatch: The dispatch to calculate the next run for.\n        _from: The time to calculate the next run from.\n\n    Returns:\n        The next run of the dispatch or None if the dispatch is finished.\n    \"\"\"\n    if (\n        not dispatch.recurrence.frequency\n        or dispatch.recurrence.frequency == Frequency.UNSPECIFIED\n    ):\n        if _from &gt; dispatch.start_time:\n            return None\n        return dispatch.start_time\n\n    # Make sure no weekday is UNSPECIFIED\n    if Weekday.UNSPECIFIED in dispatch.recurrence.byweekdays:\n        _logger.warning(\n            \"Dispatch %s has UNSPECIFIED weekday, ignoring...\", dispatch.id\n        )\n        return None\n\n    count, until = (None, None)\n    if end := dispatch.recurrence.end_criteria:\n        count = end.count\n        until = end.until\n\n    next_run = rrule.rrule(\n        freq=_RRULE_FREQ_MAP[dispatch.recurrence.frequency],\n        dtstart=dispatch.start_time,\n        count=count,\n        until=until,\n        byminute=dispatch.recurrence.byminutes,\n        byhour=dispatch.recurrence.byhours,\n        byweekday=[\n            _RRULE_WEEKDAY_MAP[weekday]\n            for weekday in dispatch.recurrence.byweekdays\n        ],\n        bymonthday=dispatch.recurrence.bymonthdays,\n        bymonth=dispatch.recurrence.bymonths,\n        interval=dispatch.recurrence.interval,\n    )\n\n    return cast(datetime | None, next_run.after(_from, inc=True))\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.cancel","title":"cancel","text":"<pre><code>cancel(msg: str | None = None) -&gt; None\n</code></pre> <p>Cancel all running tasks spawned by this background service.</p> PARAMETER DESCRIPTION <code>msg</code> <p>The message to be passed to the tasks being cancelled.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>def cancel(self, msg: str | None = None) -&gt; None:\n    \"\"\"Cancel all running tasks spawned by this background service.\n\n    Args:\n        msg: The message to be passed to the tasks being cancelled.\n    \"\"\"\n    for task in self._tasks:\n        task.cancel(msg)\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.start","title":"start","text":"<pre><code>start() -&gt; None\n</code></pre> <p>Start this actor.</p> <p>If this actor is already running, this method does nothing.</p> Source code in <code>frequenz/sdk/actor/_actor.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start this actor.\n\n    If this actor is already running, this method does nothing.\n    \"\"\"\n    if self.is_running:\n        return\n    self._tasks.clear()\n    self._tasks.add(asyncio.create_task(self._run_loop()))\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.stop","title":"stop  <code>async</code>","text":"<pre><code>stop(msg: str | None = None) -&gt; None\n</code></pre> <p>Stop this background service.</p> <p>This method cancels all running tasks spawned by this service and waits for them to finish.</p> PARAMETER DESCRIPTION <code>msg</code> <p>The message to be passed to the tasks being cancelled.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>BaseExceptionGroup</code> <p>If any of the tasks spawned by this service raised an exception.</p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>async def stop(self, msg: str | None = None) -&gt; None:\n    \"\"\"Stop this background service.\n\n    This method cancels all running tasks spawned by this service and waits for them\n    to finish.\n\n    Args:\n        msg: The message to be passed to the tasks being cancelled.\n\n    Raises:\n        BaseExceptionGroup: If any of the tasks spawned by this service raised an\n            exception.\n    \"\"\"\n    if not self._tasks:\n        return\n    self.cancel(msg)\n    try:\n        await self.wait()\n    except BaseExceptionGroup as exc_group:\n        # We want to ignore CancelledError here as we explicitly cancelled all the\n        # tasks.\n        _, rest = exc_group.split(asyncio.CancelledError)\n        if rest is not None:\n            # We are filtering out from an exception group, we really don't want to\n            # add the exceptions we just filtered by adding a from clause here.\n            raise rest  # pylint: disable=raise-missing-from\n</code></pre>"},{"location":"reference/frequenz/dispatch/actor/#frequenz.dispatch.actor.DispatchingActor.wait","title":"wait  <code>async</code>","text":"<pre><code>wait() -&gt; None\n</code></pre> <p>Wait this background service to finish.</p> <p>Wait until all background service tasks are finished.</p> RAISES DESCRIPTION <code>BaseExceptionGroup</code> <p>If any of the tasks spawned by this service raised an exception (<code>CancelError</code> is not considered an error and not returned in the exception group).</p> Source code in <code>frequenz/sdk/actor/_background_service.py</code> <pre><code>async def wait(self) -&gt; None:\n    \"\"\"Wait this background service to finish.\n\n    Wait until all background service tasks are finished.\n\n    Raises:\n        BaseExceptionGroup: If any of the tasks spawned by this service raised an\n            exception (`CancelError` is not considered an error and not returned in\n            the exception group).\n    \"\"\"\n    # We need to account for tasks that were created between when we started\n    # awaiting and we finished awaiting.\n    while self._tasks:\n        done, pending = await asyncio.wait(self._tasks)\n        assert not pending\n\n        # We remove the done tasks, but there might be new ones created after we\n        # started waiting.\n        self._tasks = self._tasks - done\n\n        exceptions: list[BaseException] = []\n        for task in done:\n            try:\n                # This will raise a CancelledError if the task was cancelled or any\n                # other exception if the task raised one.\n                _ = task.result()\n            except BaseException as error:  # pylint: disable=broad-except\n                exceptions.append(error)\n        if exceptions:\n            raise BaseExceptionGroup(\n                f\"Error while stopping background service {self}\", exceptions\n            )\n</code></pre>"}]}